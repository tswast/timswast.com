<!DOCTYPE html>
<html ng-app>
<head>
<meta charset="utf-8">
<title>An introduction to Markov chains with mathematical art</title>
<link rel="stylesheet" type="text/css" href="../../../../../css/blog.css" />
<link rel="stylesheet" type="text/css" href="../../../../../third_party/katex/katex.min.css" />
<meta name="viewport" content="initial-scale=1">

<script type="text/javascript" src="../../../../../third_party/katex/katex.min.js"></script>
<script type="text/javascript" src="../../../../../third_party/katex/contrib/auto-render.min.js"></script>
<script src="../../../../2013/js/angular.min.js"></script>
<script src="js/controllers.js"></script>
</head>

<body class="h-entry" ng-controller="MarkovCtrl" onload="myRender()">
<div id="content-header">
  <h1 class="p-name">An introduction to Markov chains with mathematical art</h1>
  <a href="/" rel="author" class="p-author h-card"><img
  src="/img/profile.png" class="u-photo u-pixel-art icon"> Tim Swast</a> on
  <time class="dt-published post-date"
  datetime="2013-08-07">August 7, 2013</time>
</div>

<div class="e-content">
<p class="e-summary">In this post, you'll use Markov chains to generate
artworks and analyze the distributions of colors. This post contains
interactive elements and is best experienced with a web browser at the <a
href="/blog/2013/08/07/markov-chains-tutorial/">original post</a>.</p>

<p>A Markov chain generates a random sequence of states; it is a
stochastic model which changes state over discrete time. It has a set
of states, a matrix of transition probabilities, and its transitions
depend only on the current state and not further history.
</p>

<p>Play with this JavaScript widget I have written. States are represented
by colors and follow a <a
href="http://en.wikipedia.org/wiki/Hilbert_curve">Hilbert curve</a> to fill
the image.. Transition probabilities are shown as per-thousands. If the sum
of the row is less than 100%, the remaining probability adds to the
transition keeping the state the same.
</p>

 <form name="myForm">
     <table>
         <tr>
             <td></td>
             <td>To 1</td>
             <td>To 2</td>
             <td>To 3</td>
             <td>To 4</td>
             <td>To 5</td>
         </tr>
         <tr ng-repeat="row in transitionMatrix">
             <td>State {{$index + 1}}</td>
             <td ng-repeat="cell in row.transitions">
                 <input type="number"
                     ng-model="cell.value"
                    min="0" max="1000">
             </td>
             <td>
                 <input type="text" ng-model="row.color" />
                 <div style="background-color: {{row.color}}; width: 1em">&nbsp;</div>
             </td>
         </tr>
     </table>
     Initial state: <input type="number" name="initialState" ng-model="initialState"
                min="1" max="5" required>
     <button ng-click="reset()">Redraw with current T</button>
</form>

<canvas id="tutorial" width="512" height="512"></canvas>

<p>
    We can define Markov chains formally as well. Assume we have a set of \(n\) states,
</p>
\[
S = \{ 1, 2, 3, \dots, n \}.
\]
<p>
    The Markov chain generates a random sequence,
</p>
\[
\{x_1, x_2, \dots, x_k, x_{k+1}, \dots \}.
\]
<p>
    The probabilities of \(x_1\) being in any particular state follow an initial distribution, \(\{a_k\}.\) State transitions depend only on the previous state, that is, we only care about the conditional probabilities,
</p>
\[ P[x_{m+1}=j | x_{m}=i], \forall i,j \in S. \]
<p>
    Therefore, we can represent a Markov chain by its transition matrix,
</p>
\[ T =
\begin{pmatrix} p_{11} &amp; p_{12} &amp; \dots &amp; p_{1n}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
p_{n1} &amp; p_{n2} &amp; \dots &amp; p_{nn}\end{pmatrix}, \]
<p>
    where \(p_{ij} = P[x_{m+1}=j | x_{m}=i].\)
</p>

<h1>Applications of Markov chains</h1>

<p>Besides being useful for making somewhat unique artwork, Markov chains
are reasonable models of many real-world processes. For example, James
Montgomery shows how they can be used to model <a
href="http://www.ssc.wisc.edu/~jmontgom/markovchains.pdf">Social mobility</a>
in his textbook on Mathematical Models of Social Systems. </p>

<p>In the social mobility model, time represents the generation and the
state represents the social class. Transition properties represent the
probability that offspring will be of a certain class given the parents'
social class. Even though this model does not represent population growth
through reproduction, it is a good first approximation.

<h1>Analysis of Markov chains.</h1>
<p>By the way states are updated, we can see that the distribution for
states at step \(i\) will be

<p>
\[ a T^i, \]

<p>where \(a\) is the initial distribution represented as a row vector, and
\(T\) is the transition probabilities matrix.

<p>In many Markov chains, this distribution tends toward something called a
stationary distribution, \(\pi.\) Where,

<p>
\[ a T^i \to \pi = \pi T. \]

<p>Note that \(\pi\) is invariant when multiplied by the transition matrix,
\(T.\) This is why it is called a stationary distribution. </p>

<h2>How will the colors be distributed in a particular drawing?</h2>
<p> We can try finding the stationary distribution of the example transition
matrix first shown on this page. </p>

<p>
\[ T = \begin{pmatrix}
0.99 &amp; 0.01 &amp; 0 \\
0.01 &amp; 0.98 &amp; 0.01 \\
0.01 &amp; 0    &amp; 0.99
\end{pmatrix} \]

<p>
    In Matlab, we can try various powers of \(T\) to see toward which distribution it may converge.
</p>
<pre><code>EDU>> a = [ 1 0 0 ];
EDU>> T = [ .99 .01 0
.01 .98 .01
.01 0   .99];

EDU>> a*T
ans =
    0.9900    0.0100         0

EDU>> a*T^2
ans =
    0.9802    0.0197    0.0001

EDU>> a*T^20
ans =
    0.8338    0.1512    0.0150

EDU>> a * T^100
ans =
    0.5663    0.2845    0.1492

EDU>> a * T^200
ans =
    0.5088    0.2635    0.2277

EDU>> a * T^400
ans =
    0.5002    0.2506    0.2493

EDU>> a*T^1000
ans =
    0.5000    0.2500    0.2500
</code></pre>
<p>
    We can see that the Markov chain will end up with about \(1/2\) in state 1, and \(1/4\) each in states 2 and 3.
</p>

<p>
    You can try this out on the current transition matrix by entering the following in Matlab.
</p>
<div style="font-family: monospace;">
    EDU>> a = [<span ng-repeat="iterState in [1,2,3,4,5]">
    {{ 1.0 * (initialState == iterState)}}
    </span>
    ];<br>
    EDU>> T = [...
    <div ng-repeat="row in transitionMatrix">
        <span ng-repeat="cell in row.transitions">
            {{cell.value / 1000}}
        </span>
    </div>
    ];<br>
    EDU>> a * T^1000<br>
    ans = ???
</div>


<h2>But proportions aren't everything...</h2>
<p>
    Consider the following transition matrices.
</p>

<p>
\[ A = \begin{pmatrix}
0.01 &amp; 0.99 \\
0.99 &amp; 0.01
\end{pmatrix} \]

<img src="two-state-alternate.png"
    alt="a nearly checkerboard drawing." />
<pre><code>EDU>> a = [1 0];
EDU>> T = [0.01 0.99
0.99 0.01];

EDU>> a * T^10000
ans =
    0.5000    0.5000</code></pre>

<p>
\[ B = \begin{pmatrix}
0.5 &amp; 0.5 \\
0.5 &amp; 0.5
\end{pmatrix} \]

<img src="two-state-noise.png" alt="random white noise." />

<pre><code>EDU>> a = [1 0];
EDU>> T = [0.5 0.5
0.5 0.5];

EDU>> a * T^10000
ans =
    0.5000    0.5000</code></pre>

<p>
\[ C = \begin{pmatrix}
0.99 &amp; 0.01 \\
0.01 &amp; 0.99
\end{pmatrix} \]
<img id="image-2-state-sticky" class="u-pixel-art u-photo"
  src="two-state-sticky.png" alt="choice of colors is sticky." />

<pre><code>EDU>> a = [1 0];
EDU>> T = [0.99 0.01
0.01 0.99];

EDU>> a * T^10000
ans =
    0.5000    0.5000</code></pre>

        <p>
            The results of these transition matrices look very different, and yet their long-run distributions are the same, with half the time spent in each state. What is clearly different is how long it takes before the Markov chain transitions from state 1 to state 2. (Note that since the transition matrices are symmetric, this is the same as saying the time for it to transition from state 2 to state 1.)
        </p>

        <p>
            David Anderson shows a method for finding the average time to transition between states on page 75-78 of Chapter 3 in
            <a href="http://www.math.wisc.edu/~anderson/605F13/605F13.html">
                Stochastic Methods for Biology.
            </a> First, consider the the ending state to be absorbing.
        </p>
        \[  \begin{pmatrix}
        0.99 &amp; 0.01 \\
        0.01 &amp; 0.99
        \end{pmatrix} \to
        \begin{pmatrix}
        0.99 &amp; 0.01 \\
        0    &amp; 1
        \end{pmatrix}
        \]

        <p>
            Next, we can rearrange the matrix such that the transitional states are grouped together in a substochastic submatrix, \(Q\).
        </p>
        \[
            \begin{pmatrix}
            1    &amp; 0 \\
            0.01 &amp; 0.99
            \end{pmatrix},
            Q = \begin{pmatrix}
            0.99
            \end{pmatrix}
        \]
        <p>
            We can then take the inverse of the matrix I - Q to find the number of visits if starting on the state corresponding to the row. Since there is just one transitional state in this example, it is quite easy to do, since the submatrix is actually just a scalar.. \((1 - 0.99)^{-1} = 100\). That is, if we start in state 1, the expected value for the time to leave state 1 is 100 time steps.
        </p>

        <h2>Another example of expected visits.</h2>
        <p>
            Consider this three-state Markov chain transition matrix.
        </p>
        \[ T = \begin{pmatrix}
        0.01 &amp; 0.99 &amp; 0 \\
        0    &amp; 0.01 &amp; 0.99 \\
        0.99 &amp; 0    &amp; 0.01
        \end{pmatrix} \]
        <p>
            It generates a picture like this.
        </p>
        <img id="image-3-state" class="u-pixel-art u-photo"
            src="three-state-alternate.png"
            alt="Something like a three-color checkerboard." />
        <p>
            How long will it take to transition to pink?
        </p>
        \[
            \begin{pmatrix}
            0.01 &amp; 0.99 &amp; 0 \\
            0    &amp; 0.01 &amp; 0.99 \\
            0.99 &amp; 0    &amp; 0.01
            \end{pmatrix}
            \to
            \begin{pmatrix}
            0.01 &amp; 0.99 &amp; 0 \\
            0    &amp; 0.01 &amp; 0.99 \\
            0    &amp; 0    &amp; 1
            \end{pmatrix}
        \]
        <p>
            Rearrange to put state 3 in the upper-left.
        </p>
        \[
            \begin{pmatrix}
            1    &amp; 0    &amp; 0 \\
            0    &amp; 0.01 &amp; 0.99 \\
            0.99 &amp; 0    &amp; 0.01
            \end{pmatrix},
            Q = \begin{pmatrix}
            0.01 &amp; 0.99 \\
            0    &amp; 0.01
            \end{pmatrix}
        \]
        <p>
            Use Matlab to find \((I - Q)^{-1}\).
        </p>
        <pre><code>EDU>> Q = [0.01 0.99
0 0.01];
EDU>> (eye(2) - Q)^-1
ans =
    1.0101    1.0101
         0    1.0101
</code></pre>
        <p>
            So, if we start in state 1, we expect to spend \(\approx 1.01\) time steps in each of states 1 and 2. Thus, we expect to spend just over 2 time steps to  transition from state 1 to state 3.
        </p>

        <h1>References</h1>

        <p>
            This project was built using HTML and JavaScript. It depends on a library called MathJax to convert LaTeX equations into pretty HTML. For graphics, it uses AngularJS to bind values to elements of the page, and it uses the HTML5 web canvas to color individual pixels dynamically.
        </p>
        <ul>
            <li>
                MathJax -
                <a href="http://www.mathjax.org/">
                    http://www.mathjax.org/
                </a>
            </li>
            <li>
                AngularJS -
                <a href="http://angularjs.org/">
                    http://angularjs.org/
                </a>
            </li>
            <li>
                HTML5 web canvas documentation -
                <a href="https://developer.mozilla.org/en-US/docs/HTML/Canvas">
                    https://developer.mozilla.org/en-US/docs/HTML/Canvas
                </a>
            </li>
        </ul>

        <p>
            More information about the mathematics of Markov chains is available here:
        </p>
        <ul>
            <li>
                Anderson, David.
                <a href="http://www.math.wisc.edu/~anderson/605F13/605F13.html">
                Stochastic Methods for Biology.
                </a> 2013</li>
            <li>
                Montgomery, James.
                <a href="http://www.ssc.wisc.edu/~jmontgom/376textbook.htm">
                    Mathematical Models of Social Systems
                </a>
            </li>
            <li>
                Resnick, Sidney I.
                <em>Adventures in stochastic processes.</em>
                Boston: Birkh√§user, 1992. Print.
                p60-173.
            </li>
        </ul>



        <script>
            // window.requestAnimationFrame is useful when creating
            // programmatic animations, but it is not supported in all browsers.
            // Paul Irish provides this shim layer with setTimeout fallback.
            // http://www.paulirish.com/2011/requestanimationframe-for-smart-animating/
            window.requestAnimFrame = (function(){
              return  window.requestAnimationFrame       ||
                      window.webkitRequestAnimationFrame ||
                      window.mozRequestAnimationFrame    ||
                      function( callback ){
                        window.setTimeout(callback, 1000 / 60);
                      };
            })();


        // Functions for working with Hilbert Curves.
        // Copied from Wikipedia.
        // http://en.wikipedia.org/wiki/Hilbert_curve#Applications_and_mapping_algorithms
        //convert d to (x,y)
        // n is the length of a side of the square being filled
        function d2xy(n, d) {
            var rx, ry, s,
                t=d,
                o = {};
            o.x = o.y = 0;

            for (s=1; s<n; s=s*2) {
                rx = 1 & (t/2); // note (& and ^) are bitwise operators.
                ry = 1 & (t ^ rx);
                rot(s, o, rx, ry);
                o.x += s * rx;
                o.y += s * ry;
                t /= 4;
            }
            return o;
        }

        //rotate/flip a quadrant appropriately
        function rot(n, o, rx, ry) {
            if (ry == 0) {
                if (rx == 1) {
                    o.x = n-1 - o.x;
                    o.y = n-1 - o.y;
                }

                //Swap x and y
                var t  = o.x;
                o.x = o.y;
                o.y = t;
            }
        }

            // How should we represent a Markov chain?
            // There are some number of states. These each have an associated color.
            colors = [
                "#ffffff",
                "#000000",
                "rgba(100, 0, 200, 1.0)",
                "rgba(200, 0, 100, 1.0)",
                "rgba(250, 150, 0, 1.0)"
            ];
            transitionMatrix = [
                [0.1, 0.9],
                [0.1, 0.9]
            ];
            currentstate = 0;
            function updateMarkovChain() {
                var transitionSample = Math.random(),
                    previousTransitions = 0,
                    i = 0,
                    transitions = transitionMatrix[currentstate];

                for (i in transitions) {
                    previousTransitions += transitions[i];
                    if (transitionSample <= previousTransitions) {
                        currentstate = i;
                        break;
                    }
                }
            }

            // Start drawing to the canvas.
            // See the tutorial at
            // https://developer.mozilla.org/en-US/docs/Web/Guide/HTML/Canvas_tutorial/Basic_usage
            currentstep = 0;
            function step(timestamp) {
                var canvas = document.getElementById('tutorial');
                var ctx = canvas.getContext('2d');

                for (var i=0 ; i < 64 ; i++) {
                    // Draw.
                    var pos = d2xy(512, currentstep);
                    ctx.fillStyle = colors[currentstate];
                    ctx.fillRect (pos.x, pos.y, 1, 1);

                    // Get next state.
                    currentstep = currentstep + 1;
                    updateMarkovChain();
                }

                // keep animating.
                if (currentstep < 512*512) {
                    window.requestAnimFrame(step);
                }
            }
            window.requestAnimFrame(step);
        </script>

<p> This post was created as part of a project for <a
href="http://www.math.tamu.edu/~mpilant/math696/Summer-2013-Syllabus.html">
Texas A&amp;M Math 696. </a>
</div>

<footer>
  Copyright 2013. Released under <a
  href="https://creativecommons.org/licenses/by/4.0/">Creative Commons
  Attribution License</a>.
</footer>

<!-- Find and render LaTeX using KaTeX auto-render plugin. -->
<script>
    renderMathInElement(document.body);
</script>
</body>
</html>
